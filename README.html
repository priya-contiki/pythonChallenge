<h1>Instructions</h1>

<h2>Getting Started</h2>

<h3>Linux</h3>

<p>To complete this coding challenge make sure you have python3 installed on your system.</p>

<p>All that remains to be done is run:</p>

<pre><code>make init
</code></pre>

<p>This will install a virtualenv in python3. Thereafter a new virtualenv called "coding_challenge" will be created. All required packages for this challenge will be installed in this virtualenv.</p>

<p>Note: This will only create the virtualenv. To activate it you will have to run:</p>

<pre><code>source coding_challenge/bin/activate
</code></pre>

<h3>Windows</h3>

<p>For windows users we unfortunately do not have an automated script. Please ensure all packages listed in requiremenmts.txt are met and that you are running Python 3.6. For Task 3 simply run <code>python3 resources/process_manager.py</code></p>

<h2>Task 1</h2>

<p>Your team has been asked to manage a server which acts as a micro service for a dating app. Its goal is to return a list of profiles which fit best to the input profile. It works by creating an n-dimensional vector for each profile. These vectors are commonly referred to as embeddings and lie at the heart of modern deep learning. They contain an abstract notion of the meaning of the data by training a vectorizer function on some dataset. </p>

<p>A separate datascience team has provided you with this vectorization function (found in utils/vectorize.py). They have also been kind enough to provide you with a pickle file containing all the dating profiles on your application. </p>

<p>The micro service will have an endpoint called <code>/recommend/_id/n</code> where <code>_id</code> is a unique id of each profile in the database. Your goal is to create the functionality for this endpoint and have it return the <code>n</code> nearest neighbours.</p>

<p>Your colleague has already implemented most of the functionality regarding the server setup.
He couldnâ€™t quite get the functionality right and has gone and simply hard coded some dummy data of how the server should respond.
Your job is to finish the functionality in endpoints.py . To do this you may create any additional external/auxiliary methods or classes as you see fit as long as the /recommend/ endpoint is left unchanged.</p>

<h3>Acceptance Criteria:</h3>

<ul>
<li>Your module successfully reads in pickle file from disk and stores the contents in memory</li>
<li>The Recommend endpoint returns the correct n nearest neighbour of an incoming profile by cosine distance.</li>
<li>All edge cases are handled intelligently and proactively</li>
</ul>

<h2>Task 2</h2>

<p>While the solution above is probably sufficient for our current number of vectors it does not scale if the task is to find nearest neighbours of 1M+ vectors. 
To do this efficiently your team has decided to use the <a href="https://github.com/spotify/annoy">annoy</a> library which is implemented in C++ for speed. </p>

<p>This task will not require your understanding of the inner workings of the annoy library beyond the following:
Annoy works by first adding all vectors using the <code>add_item(i, v)</code> function. It only accepts integers (0-n) as keys to the vectors so you need to store a separate mapping file which maps these integers to their actual value. Thereafter it builds an index for fast lookup. Once the index has been built you cannot add further vectors to it. This index can be written and read to and from disk using the save and load function respectively. A built index has the method <code>get_nns_by_vector()</code> which returns the n nearest neighbours of that particular vector as well as the distance.</p>

<p>However using this library also presents its own challenges. 
As index files are immutable after they have been built we will have to keep creating new indices and writing them to disk.
Creating new indices is computationally expensive so it should be moved to a separate microservice.
Reading in a new index file can take several seconds as it is done via slow IO operations.</p>

<p>As our customers demand that they always have fast response times your team has come up with 3 potential solutions. </p>

<p>Your task is to analyze each solution outline and to compare them against one another. Furthermore you should come up with your own best solution and compare them to your colleagues. </p>

<p>Please do so in structured prose using 500 words or less.</p>

<h3>Solution 1</h3>

<p>We will have one main process running the server and communicating with the outside world. This main process will have to child processes p0 and p1. When they are started p0 becomes the so-called fetch process. Its task is to find and read the latest index file. Once it has done so it lets the main process know it is ready to handle requests. At this point the main process assigns p0 the role of the answer process. p1 is assigned the fetch process role. Once p1 is finished fetching all (potentially new) indices it will become the answer process and p0 will be instructed to fetch once more. </p>

<p>These 2 processes will continue to switch roles indefinitely. The main process will always use the subprocess which has most recently finished its fetch process in order to handle requests.</p>

<h3>Solution 2</h3>

<p>We will have one main process running the server and communicating with the outside world. There will be an Auxiliary process. The auxiliary processes task is to continuously look for new index files. As soon as it discovers one it will spawn a new process to read in this index. Once the new process completes the index read it will tell the Auxiliary process that is now ready to handle requests.</p>

<p>The Auxiliary process and the Main process have a shared piece of memory. Upon receiving the newly spawned processes ready signal the Auxiliary process writes a Queue object to the shared memory which the main process can use to answer requests.</p>

<p>All that is left to do for the Main process upon receiving a new request is selecting which child process it will use to answer this request. </p>

<h3>Solution 3</h3>

<p>Annoy gives an option to mmap the index file instead of reading it into memory completely. If you are unfamiliar with what mmap does please check wikipedia. This will dramatically increase the speed at which indices are loaded thus solving our problem.</p>

<h3>Solution 4</h3>

<p>Your solution.</p>

<h2>Task 3</h2>

<p>Your colleague has begun to implement a skeleton for solution 1 from the task above. Somehow he has introduced a bug which makes the processes unresponsive. He has asked for your help to get it working. </p>

<p>The goal is only to have the exoskeleton in place which handles the logic of switching the role of each task. The actual operations performed by each role need not be implemented.</p>

<p>To run the code please run:</p>

<pre><code>make multi
</code></pre>

<h2>Task 4</h2>

<p>In the refactor folder is a file named <code>normalize.py</code> which is used to normalize texts for various languages. 
It needs to be refactored desperately. Without changing any of the functionality please do so paying special attention to readability, reusability and testability. In the accompanying markdown file <code>normalize.md</code> please motivate your 3 biggest code changes. </p>

<h2>Task 5 - Bonus</h2>

<p>In the bug_fix folder you will find a file named <code>groceries.py</code>. The Groceries class contains a small bug which leads to unexpected behaviour. Your task is to identify and eliminate the bug.</p>
